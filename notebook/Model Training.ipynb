{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c2650f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# i am importing all the models to know which is the best model for my data\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "# evalution matrices as the output is a continous data we are importing these evalution matrices if categorical we need\n",
    "#  binary,categorical entropy\n",
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "#models starting\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import Lasso,Ridge\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from xgboost import XGBRegressor\n",
    "from catboost import CatBoostRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ab4fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load dataset\n",
    "df = pd.read_csv(r\"C:\\Users\\Yesuraju\\Desktop\\MachineLearningWorkSpace\\notebook\\data\\stud.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "772e792d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first define our target and independent variables\n",
    "X = df.drop(\"reading_score\",axis=1)\n",
    "Y = df[\"reading_score\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "102de19d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# here divide our columns into categorical and non-categorical\n",
    "numerical_features = X.select_dtypes(exclude=\"object\").columns\n",
    "categorical_features = [col for col in X.columns if X[col].dtype == \"object\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8ef03139",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gender',\n",
       " 'race_ethnicity',\n",
       " 'parental_level_of_education',\n",
       " 'lunch',\n",
       " 'test_preparation_course']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c696aa38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating a pipeline for both categorical and standardization\n",
    "from sklearn.preprocessing import OneHotEncoder,StandardScaler\n",
    "# this column transformers will create the pipeline for both categorical and standarization\n",
    "from sklearn.compose import ColumnTransformer\n",
    "numerical_standard = StandardScaler()\n",
    "cate_one = OneHotEncoder()\n",
    "preprocessor = ColumnTransformer(\n",
    "        [\n",
    "                (\"OneHotEncoder\",cate_one,categorical_features),\n",
    "                (\"StandardScaler\",numerical_standard,numerical_features)\n",
    "        ]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0aa65e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# applying both preprocessors to the training data set\n",
    "X = preprocessor.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68906dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data set into train test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test = train_test_split(X,Y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "411e54ba",
   "metadata": {},
   "source": [
    "# creating the evaltion function to find the accuracy of the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56491bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score,mean_absolute_error\n",
    "def eval_func(y_predict,y_true):\n",
    "        mae = mean_absolute_error(y_true,y_predict)\n",
    "        r2_square = r2_score(y_true,y_predict)\n",
    "        return mae,r2_square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c26557c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Name  Linear Regression\n",
      "Training evalution matrices\n",
      "train_mae:  3.24625\n",
      "train_r2_score:  0.9167761757679435\n",
      "\n",
      "\n",
      "testing evalution matrices\n",
      "test_mae: 3.091875\n",
      "testing_r2_score: 0.9241673194304232\n",
      "\n",
      "\n",
      "Model Name  Lasso\n",
      "Training evalution matrices\n",
      "train_mae:  3.5112499908580004\n",
      "train_r2_score:  0.8863885953074425\n",
      "\n",
      "\n",
      "testing evalution matrices\n",
      "test_mae: 3.2907847918436492\n",
      "testing_r2_score: 0.9044007088802761\n",
      "\n",
      "\n",
      "Model Name  Ridge\n",
      "Training evalution matrices\n",
      "train_mae:  3.2307806320523236\n",
      "train_r2_score:  0.9186198294652381\n",
      "\n",
      "\n",
      "testing evalution matrices\n",
      "test_mae: 3.064983081263207\n",
      "testing_r2_score: 0.9261291830544833\n",
      "\n",
      "\n",
      "Model Name  K-Neighbors Regressor\n",
      "Training evalution matrices\n",
      "train_mae:  3.8175\n",
      "train_r2_score:  0.8469254393600005\n",
      "\n",
      "\n",
      "testing evalution matrices\n",
      "test_mae: 4.662999999999999\n",
      "testing_r2_score: 0.757100942694698\n",
      "\n",
      "\n",
      "Model Name  Decision Tree\n",
      "Training evalution matrices\n",
      "train_mae:  1.2983099999999999\n",
      "train_r2_score:  0.9868620617546381\n",
      "\n",
      "\n",
      "testing evalution matrices\n",
      "test_mae: 3.4544116666666667\n",
      "testing_r2_score: 0.9114692259023004\n",
      "\n",
      "\n",
      "Model Name  Random Forest Regressor\n",
      "Training evalution matrices\n",
      "train_mae:  1.30779\n",
      "train_r2_score:  0.986800674039381\n",
      "\n",
      "\n",
      "testing evalution matrices\n",
      "test_mae: 3.4686766666666666\n",
      "testing_r2_score: 0.9119856081660278\n",
      "\n",
      "\n",
      "Model Name  XGBRegressor\n",
      "Training evalution matrices\n",
      "train_mae:  0.4936343240737915\n",
      "train_r2_score:  0.997544112290821\n",
      "\n",
      "\n",
      "testing evalution matrices\n",
      "test_mae: 3.8036774158477784\n",
      "testing_r2_score: 0.8940590374887847\n",
      "\n",
      "\n",
      "Model Name  CatBoosting Regressor\n",
      "Training evalution matrices\n",
      "train_mae:  1.7998723602385436\n",
      "train_r2_score:  0.9745220676013197\n",
      "\n",
      "\n",
      "testing evalution matrices\n",
      "test_mae: 3.3944566600609845\n",
      "testing_r2_score: 0.9090054209092792\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# here we are not using any hyperparameter function first we will select model then will hyper parameter tuning on that \n",
    "# model\n",
    "models = {\n",
    "    \"Linear Regression\": LinearRegression(),\n",
    "    \"Lasso\": Lasso(),\n",
    "    \"Ridge\": Ridge(),\n",
    "    \"K-Neighbors Regressor\": KNeighborsRegressor(),\n",
    "    \"Decision Tree\": RandomForestRegressor(),\n",
    "    \"Random Forest Regressor\": RandomForestRegressor(),\n",
    "    \"XGBRegressor\": XGBRegressor(), \n",
    "    \"CatBoosting Regressor\": CatBoostRegressor(verbose=False),\n",
    "}\n",
    "\n",
    "for model_name, model_func in models.items():\n",
    "        # feeding both train set and test set to the model\n",
    "        # training the model\n",
    "        model_func.fit(x_train,y_train)\n",
    "        y_train_pred = model_func.predict(x_train)\n",
    "        y_test_pred = model_func.predict(x_test)\n",
    "        train_mae,train_r2_score = eval_func(y_train,y_train_pred)\n",
    "        test_mae,test_r2_score = eval_func(y_test,y_test_pred)\n",
    "        print(\"Model Name \", model_name)\n",
    "        print(\"Training evalution matrices\")\n",
    "        print(\"train_mae: \",train_mae)\n",
    "        print(\"train_r2_score: \",train_r2_score)\n",
    "        print(\"\\n\")\n",
    "        print(\"testing evalution matrices\")\n",
    "        print(\"test_mae:\",test_mae)\n",
    "        print(\"testing_r2_score:\",test_r2_score)\n",
    "        print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf393967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by seeing the above data we can conclude that the ridge regression is the best for our data as it has low varince compared to \n",
    "# other models \n",
    "# it is having same trining and testing accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8091d885",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for this ridge model we will do hyperparameter tuning to select best parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea438c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
